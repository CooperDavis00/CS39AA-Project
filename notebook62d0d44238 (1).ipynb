{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":8.31423,"end_time":"2023-11-13T05:57:07.455887","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-13T05:56:59.141657","version":"2.4.0"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project Part 1\n\n[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/sgeinitz/CS39AA-project/blob/main/project_part1.ipynb)\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgeinitz/CS39AA-project/blob/main/project_part1.ipynb)","metadata":{"papermill":{"duration":0.005852,"end_time":"2023-11-13T05:57:02.734682","exception":false,"start_time":"2023-11-13T05:57:02.72883","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 1. Introduction/Background\n\nFor my project I will be using a couple different song datasets that contain the song title, the artist, and the genre of the song. I will also be creating my own dataset with my personal spotify data of liked songs. This personal dataset will have the same parameters along with a parameter that will say 1 or 0 if I like the song or do not. All in all, I am using song data to predict if I would like a song based on my own liked songs, and the model will use binary classification to predict if I like the song or not. \n\nhere are links to the datasets I plan to use, one will be used for predictions but I am testing out a few different ones. \n\n1.  https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset\n\n2. https://www.kaggle.com/datasets/byomokeshsenapati/spotify-song-attributes\n\n3. https://www.kaggle.com/datasets/undefinenull/million-song-dataset-spotify-lastfm ","metadata":{"papermill":{"duration":0.004893,"end_time":"2023-11-13T05:57:02.745208","exception":false,"start_time":"2023-11-13T05:57:02.740315","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 2. Exploratory Data Analysis\n\nfor part 1 of my project I will be using this dataset: https://www.kaggle.com/datasets/byomokeshsenapati/spotify-song-attributes\n\nIn the future I will be using a more refined dataset with more entries, this one has about 4600 so it is a good start for now. \n","metadata":{"papermill":{"duration":0.00486,"end_time":"2023-11-13T05:57:02.755316","exception":false,"start_time":"2023-11-13T05:57:02.750456","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# import all of the python modules/packages you'll need here\nimport pandas as pd\nimport numpy as nm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report\n\n# ...","metadata":{"papermill":{"duration":1.964922,"end_time":"2023-11-13T05:57:04.725382","exception":false,"start_time":"2023-11-13T05:57:02.76046","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-13T18:40:15.058214Z","iopub.execute_input":"2023-11-13T18:40:15.059356Z","iopub.status.idle":"2023-11-13T18:40:15.065457Z","shell.execute_reply.started":"2023-11-13T18:40:15.059316Z","shell.execute_reply":"2023-11-13T18:40:15.064391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is the dataset found from kaggle linked above. Here i read it into a file and format it so the only values displayed are trackName, artistName, and genre. Then I add a like column populated with all zeros since these are the songs i will be predicting and they start with not liked. ","metadata":{"papermill":{"duration":0.005641,"end_time":"2023-11-13T05:57:04.736723","exception":false,"start_time":"2023-11-13T05:57:04.731082","status":"completed"},"tags":[]}},{"cell_type":"code","source":"song_data = '/kaggle/input/spotify-song-attributes/Spotify_Song_Attributes.csv'\ndf = pd.read_csv('https://raw.githubusercontent.com/CooperDavis00/CS39AA-Project/main/Spotify_Song_Attributes.csv')\ndf = df.drop(['msPlayed', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'type', 'id', 'uri', 'track_href', 'analysis_url', 'duration_ms'], axis=1)\ndf['like'] = 0\ndf = df.dropna(subset=['genre'])\ndf.head()","metadata":{"papermill":{"duration":0.258009,"end_time":"2023-11-13T05:57:05.000089","exception":false,"start_time":"2023-11-13T05:57:04.74208","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-13T18:40:15.067742Z","iopub.execute_input":"2023-11-13T18:40:15.068251Z","iopub.status.idle":"2023-11-13T18:40:15.436915Z","shell.execute_reply.started":"2023-11-13T18:40:15.068204Z","shell.execute_reply":"2023-11-13T18:40:15.435620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is my dataset generated from my own spotify playlist with the same columns and i added a like column populated with ones. \n","metadata":{"papermill":{"duration":0.005646,"end_time":"2023-11-13T05:57:05.01193","exception":false,"start_time":"2023-11-13T05:57:05.006284","status":"completed"},"tags":[]}},{"cell_type":"code","source":"liked_song_data = '/kaggle/input/liked-spotify-songs/liked_songs_with_genre.csv'\ndf1 = pd.read_csv('https://raw.githubusercontent.com/CooperDavis00/CS39AA-Project/main/liked_songs_with_genre.csv')\ndf1['like'] = 1\n\ndf1.head(25)","metadata":{"papermill":{"duration":0.030201,"end_time":"2023-11-13T05:57:05.048447","exception":false,"start_time":"2023-11-13T05:57:05.018246","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-13T18:41:36.735317Z","iopub.execute_input":"2023-11-13T18:41:36.735716Z","iopub.status.idle":"2023-11-13T18:41:36.803177Z","shell.execute_reply.started":"2023-11-13T18:41:36.735685Z","shell.execute_reply":"2023-11-13T18:41:36.801834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am counting the different genres and the amount of times each one is displayed. I then display a graph with the top 15 genres and an other category. ","metadata":{"papermill":{"duration":0.005668,"end_time":"2023-11-13T05:57:05.060416","exception":false,"start_time":"2023-11-13T05:57:05.054748","status":"completed"},"tags":[]}},{"cell_type":"code","source":"combined_df = pd.concat([df1, df], ignore_index=True)\n\n# Display the count of each genre in the dataset\ngenre_counts = combined_df['Genre'].value_counts()\n\ngenre_description = combined_df['Genre'].describe()\n\nprint(\"Summary of Genre Information:\")\nprint(genre_description)\n\n\n# Keep the top 15 genres, and group the rest as \"Other\"\ntop_genres = genre_counts.head(15)\nother_genres_count = genre_counts[15:].sum()\n\n# Add \"Other\" to the top genres\ntop_genres['Other'] = other_genres_count\n\n# Plot a bar chart\nplt.figure(figsize=(12, 6))\ntop_genres.plot(kind='bar', color='skyblue')\nplt.title('Top 15 Genres and Other in the Dataset')\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.xticks(rotation=45, ha='right')\nplt.show()","metadata":{"papermill":{"duration":0.535339,"end_time":"2023-11-13T05:57:05.601645","exception":false,"start_time":"2023-11-13T05:57:05.066306","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-13T18:40:15.669593Z","iopub.execute_input":"2023-11-13T18:40:15.669939Z","iopub.status.idle":"2023-11-13T18:40:16.160472Z","shell.execute_reply.started":"2023-11-13T18:40:15.669909Z","shell.execute_reply":"2023-11-13T18:40:16.159552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this cell i am setting up my variable and training with the logisticRegression model. Then I display the shape and initial accuracy. \n","metadata":{"papermill":{"duration":0.006837,"end_time":"2023-11-13T05:57:05.615684","exception":false,"start_time":"2023-11-13T05:57:05.608847","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Assuming 'Genre' is the only feature for simplicity\nX = combined_df['Genre'].copy()\ny = combined_df['like'].copy()\n\n# Split the data into training and testing sets\nX_train_raw, X_val_raw, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=21)\n\n# Create a TF-IDF vectorizer\ntfidf_vectorizer = TfidfVectorizer()\n\n# Transform the training and validation sets\nX_train = tfidf_vectorizer.fit_transform(X_train_raw.values.astype('U')).toarray()\nX_val = tfidf_vectorizer.transform(X_val_raw.values.astype('U')).toarray()\n\nprint(f\"X_train.shape = {X_train.shape}\")\nprint(f\"X_val.shape = {X_val.shape}\")\n\n# Create a logistic regression model\nmodel = LogisticRegression()\n\n# Train the model on the training data (liked songs)\nmodel.fit(X_train, y_train)\n\n# Make predictions on the additional songs dataset\ny_pred = model.predict(X_val)\n\n# Evaluate the model\naccuracy = accuracy_score(y_val, y_pred)\nclassification_report_str = classification_report(y_val, y_pred)\n\nprint(f\"Model Accuracy: {accuracy}\")\nprint(\"Classification Report:\\n\", classification_report_str)","metadata":{"papermill":{"duration":0.228367,"end_time":"2023-11-13T05:57:05.851274","exception":false,"start_time":"2023-11-13T05:57:05.622907","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-13T18:40:16.163241Z","iopub.execute_input":"2023-11-13T18:40:16.163622Z","iopub.status.idle":"2023-11-13T18:40:16.393277Z","shell.execute_reply.started":"2023-11-13T18:40:16.163589Z","shell.execute_reply":"2023-11-13T18:40:16.392087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"testing the accuracy of the model. ","metadata":{"papermill":{"duration":0.014654,"end_time":"2023-11-13T05:57:05.881169","exception":false,"start_time":"2023-11-13T05:57:05.866515","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model = LogisticRegression()\nmodel = model.fit(X_train, y_train)\n\npredictions_train = model.predict(X_train)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix(y_train, predictions_train), display_labels=['liked', 'not liked'])\ndisp.plot()\nprint(f\"accuracy (on y_train): {accuracy_score(y_train, predictions_train):.4f}\")","metadata":{"papermill":{"duration":0.481794,"end_time":"2023-11-13T05:57:06.377965","exception":false,"start_time":"2023-11-13T05:57:05.896171","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-13T18:40:16.394844Z","iopub.execute_input":"2023-11-13T18:40:16.395585Z","iopub.status.idle":"2023-11-13T18:40:16.884221Z","shell.execute_reply.started":"2023-11-13T18:40:16.395531Z","shell.execute_reply":"2023-11-13T18:40:16.882978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_val = model.predict(X_val)\ndisp = ConfusionMatrixDisplay(confusion_matrix(y_val, predictions_val), display_labels=['liked', 'not liked'])\ndisp.plot()\nprint(f\"accuracy (on y_val): {accuracy_score(y_val, predictions_val):.4f}\")","metadata":{"papermill":{"duration":0.422822,"end_time":"2023-11-13T05:57:06.80878","exception":false,"start_time":"2023-11-13T05:57:06.385958","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-13T18:40:16.885581Z","iopub.execute_input":"2023-11-13T18:40:16.885896Z","iopub.status.idle":"2023-11-13T18:40:17.305698Z","shell.execute_reply.started":"2023-11-13T18:40:16.885868Z","shell.execute_reply":"2023-11-13T18:40:17.304443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"papermill":{"duration":0.008071,"end_time":"2023-11-13T05:57:06.825425","exception":false,"start_time":"2023-11-13T05:57:06.817354","status":"completed"},"tags":[]}}]}